<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-09-03T17:59:17+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Scribbling every Miscellaneous things  </title><subtitle> website.</subtitle><author><name>Irene Kim</name><email>irenee.jy93@gmail.com</email></author><entry><title type="html">Bert paper Review</title><link href="http://localhost:4000/nlp/Bert-paper-Review/" rel="alternate" type="text/html" title="Bert paper Review" /><published>2020-09-03T00:00:00+09:00</published><updated>2020-09-03T00:00:00+09:00</updated><id>http://localhost:4000/nlp/Bert-paper-Review</id><content type="html" xml:base="http://localhost:4000/nlp/Bert-paper-Review/">&lt;p&gt;Bert&lt;/p&gt;
&lt;h3 id=&quot;01-what-is-bert&quot;&gt;01 what is Bert?&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Bert Architecture&lt;/li&gt;
  &lt;li&gt;State of Art&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;02-bert-architecture&quot;&gt;02 Bert Architecture&lt;/h3&gt;
&lt;ol&gt;
  &lt;li&gt;Pre-training task&lt;/li&gt;
  &lt;li&gt;Input Embedding&lt;/li&gt;
  &lt;li&gt;Encoding&lt;/li&gt;
  &lt;li&gt;Fine-tuning&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;기존-자연어-처리-신경망&quot;&gt;기존 자연어 처리 신경망&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/Bert_.png&quot; alt=&quot;Git repository 신규 생성 이미지&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;RNN ( 순환 신경망 ) : 각 새로운 입력층마다 hidden layer 를 저장/수정 하여 새로운 정보를 점차 업데이트 해나아가는 신경망&lt;/li&gt;
  &lt;li&gt;LSTM : RNN의 응용모델로 각 신경망에 hidden state 와 cell state 를 더해주어 오랜시간 이전 정보를 기억&lt;/li&gt;
  &lt;li&gt;Transformer (Encoder-Decoder): 기존 RNN base 모델과 다르게 문장 전체를 입력후 각 단어의 위치를 학습하여 Encoding ( 수치화 ) 후 Decoding (번역 ) 하는 신경망&lt;/li&gt;
  &lt;li&gt;Attention: Transformer 의 응용으로 문장중 중요한 단어에 가중치를 부여&lt;/li&gt;
  &lt;li&gt;Bert : Transformer의 Encoder 에 Self Attenion 을 적용한 학습법으로  단어의 양 위치 (Bi-directional) 을 학습, 문맥의 흐름을 이해&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;bert--bi-directional-encoder-representation-from-transformers&quot;&gt;BERT ( Bi-directional Encoder Representation from Transformers)&lt;/h2&gt;

&lt;p&gt;Purpose: 문장/문단의 문맥을 이해하는 언어 이해 모델로서 사용자의 니즈에 따라 다양하게 사용할수있는 모델&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;기존의 좋은 평가를 받아온 ELMO 보다 좋은 성능&lt;/li&gt;
  &lt;li&gt;ELMO : Uni-directional LSTM Model&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;GPT : left to right, and right to left transformer model&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;NLP 의 11 개 테스크에서 state of art 기록&lt;/li&gt;
  &lt;li&gt;SQuAD 기록 갱신&lt;/li&gt;
  &lt;li&gt;사용자는 Transfer Learning 을 통해 학습된 모델을 가져와     Fine -tuning 을 통해 필요에 맞게 사용 가능하다.&lt;/li&gt;
  &lt;li&gt;Transformer 모델 기반
    &lt;ul&gt;
      &lt;li&gt;Encoder 부분 사용&lt;/li&gt;
      &lt;li&gt;Speed, Accuracy , Long-term decedency 에서 우수한 모델&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bert-architecture&quot;&gt;BERT ARCHITECTURE&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/Transformer.png&quot; alt=&quot;Git repository 신규 생성 이미지&quot; class=&quot;align-center&quot; /&gt;
‘Attention is All’ 논문에서 발표된 Transformer 모델의 Encoding 부분 차용&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Pre-training task&lt;/li&gt;
  &lt;li&gt;Fine-Tuning &lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;※ 2 가지 버전 :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Bert-Base ( L=12, H=768, A=12) &lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;Bert-Large( L=24, H=1024, A=16)&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;해당 문서에서는 Base 버전 으로 진행&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-pre---training&quot;&gt;1. Pre - training&lt;/h2&gt;

&lt;h3 id=&quot;1-pre-training-tasks&quot;&gt;1. pre-training tasks&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/pretrain.png&quot; alt=&quot;Git repository 신규 생성 이미지&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Masked Language Modelling
    &lt;ul&gt;
      &lt;li&gt;문장내의 15% 의 랜덤한 단어를 가린다 &lt;MASK&gt; 
  단
&lt;/MASK&gt;        &lt;ul&gt;
          &lt;li&gt;80% [‘MASK’] Token&lt;/li&gt;
          &lt;li&gt;10% Random 단어, 10% 정상 단어&lt;/li&gt;
          &lt;li&gt;해당 방법을 통해, mask 뿐만 아니라 정상, 랜덤 단어 역시 학습하여 모든단어에 대한 문맥 표현을 학습&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Next Sentence Prediction
        &lt;ul&gt;
          &lt;li&gt;문장 B 가 문장 A 의 바로 다음에 오는 문장이 맞는지에 대한 여부를 예측&lt;/li&gt;
          &lt;li&gt;문장의 50% 비율로 두 문장의 연결을 랜덤하게 구성&lt;/li&gt;
          &lt;li&gt;문장 B가 문장 A의 이어지는 문장일경우 IsNext 라고 레이블링, 아닐경우 NotNext
            &lt;ul&gt;
              &lt;li&gt;예) Input = [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP] LABEL = IsNext&lt;/li&gt;
              &lt;li&gt;예) Input = [CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP] Label = NotNext
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-embedding-&quot;&gt;2. Embedding :&lt;/h3&gt;

&lt;p&gt;각 단어 Token 을 Vectorize 하는 과정
&lt;img src=&quot;http://localhost:4000/assets/images/embedding.png&quot; alt=&quot;Git repository 신규 생성 이미지&quot; class=&quot;align-center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Input = Token Embedding + Segment Embedding + Position Embedding&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Position Encoding 대신 Postion embedding 사용&lt;/li&gt;
  &lt;li&gt;Token : 각 단어의 의미를 숫자세트로 표현한 Vector&lt;/li&gt;
  &lt;li&gt;Segment : 문단의 문장의 순서/위치 ( 첫번째 문장 0, 두번째 문장 1 etc)&lt;/li&gt;
  &lt;li&gt;Position:  총 문단안의 단어의 순서/위치&lt;/li&gt;
  &lt;li&gt;입력값 : 각 3개의 임베딩을 합산한 결과를
    &lt;ul&gt;
      &lt;li&gt;(Base 의 경우 768 차원의 Vector Large 의 경우 1024)&lt;/li&gt;
      &lt;li&gt;즉 단어의 의미 + 문장의 위치 + 단어의 위치를 뜻하는 768 차원의 vector 로 Embedding&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-encoding-layers&quot;&gt;3. Encoding Layers&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;http://localhost:4000/assets/images/encoding.png&quot; alt=&quot;Git repository 신규 생성 이미지&quot; class=&quot;align-center&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Multi-Head Attention : 여러 문장속 동일한/연관이 높은 단어에 가중치 를 높여주는 과정
    &lt;ol&gt;
      &lt;li&gt;768 차원의 input vector 를 12개의 head 로 나누어 각 헤드별로 64차원의 Vector 를 Q,K,V값으로 지정한다.&lt;/li&gt;
      &lt;li&gt;Q 와 K vector의 값을 곱해 연관성을 구한다.&lt;br /&gt;
예) dog Q [0.3, -0.2 0.4] * ‘The’ K [0.5, -0.9, 0.2]  = 0.4&lt;/li&gt;
      &lt;li&gt;구해진 값에 soft max 를 적용하여 0~1 사이 값으로 scaling 하여 너무높은 또는 낮은 Score 값이 사라지는 문제를 줄인다&lt;br /&gt;
예) [0.4 0,6 -0.6] –&amp;gt; [0.4 0.5 0.1]&lt;/li&gt;
      &lt;li&gt;각 구해진 softmax(score) 에 V vector 을 곱한다 (64차원)&lt;/li&gt;
      &lt;li&gt;나누어진 12개의 Head에 동일한 작업 진행후 나온 12개의 64차원 vector 를 sum 하여 최초와 동일한 768개의 vector 생성
&lt;br /&gt;
&lt;br /&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Add &amp;amp; Normalize
&lt;img src=&quot;http://localhost:4000/assets/images/addnorm.png&quot; alt=&quot;Git repository 신규 생성 이미지&quot; class=&quot;align-center&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;ResNet : 기존의 Embedding input vector 를 Self-Attention 값에 더하고 Normalize&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Normalize: 정규화로 인해, Layer를 효과적으로 Stablize
&lt;br /&gt;&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Encoding Layer  N번의 Layer 에서 반복 실행&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;task-lists&quot;&gt;Task Lists&lt;/h3&gt;

&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;Finish my changes&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;Push my commits to GitHub&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;Open a pull request
    &lt;ul class=&quot;task-list&quot;&gt;
      &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;Follow discussions&lt;/li&gt;
      &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;Push new commits&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Irene Kim</name><email>irenee.jy93@gmail.com</email></author><category term="NLP" /><category term="Bert" /><category term="Attention" /><category term="NLP" /><category term="Transformer" /><category term="Multi-head Attention" /><summary type="html">Bert 01 what is Bert? Bert Architecture State of Art</summary></entry></feed>